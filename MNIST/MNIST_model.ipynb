{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPNJs+7psbCAlleCE2QSgM3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/95-sanya-95/Summer_ML_internship/blob/main/MNIST_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hS2p7uUTG6S",
        "outputId": "42fdf396-1f98-426c-c0fe-2e89da9f7b1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.4.26)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: dm-haiku in /usr/local/lib/python3.10/dist-packages (0.0.12)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (4.9.6)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jax) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax) (1.11.4)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from dm-haiku) (1.4.0)\n",
            "Requirement already satisfied: jmp>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from dm-haiku) (0.0.4)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from dm-haiku) (0.9.0)\n",
            "Requirement already satisfied: flax>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from dm-haiku) (0.8.4)\n",
            "Requirement already satisfied: chex>=0.1.86 in /usr/local/lib/python3.10/dist-packages (from optax) (0.1.86)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.1.8)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (4.2.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (14.0.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.31.0)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.1.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.4.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (4.66.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.14.1)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.5.1)\n",
            "Requirement already satisfied: etils[enp,epath,epy,etree]>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.86->optax) (4.12.2)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.86->optax) (0.12.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0->tensorflow-datasets) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0->tensorflow-datasets) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0->tensorflow-datasets) (3.19.2)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku) (1.0.8)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku) (0.4.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku) (0.1.45)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku) (13.7.1)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku) (6.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2024.6.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow-datasets) (1.16.0)\n",
            "Requirement already satisfied: docstring-parser~=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets) (0.16)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.1->dm-haiku) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.1->dm-haiku) (2.16.1)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.7.1->dm-haiku) (1.6.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.7.1->dm-haiku) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install jax jaxlib dm-haiku optax tensorflow-datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to range [0, 1] and convert to float32\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Split data into training and validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert numpy arrays to JAX arrays\n",
        "x_train = jnp.array(x_train)\n",
        "x_val = jnp.array(x_val)\n",
        "y_train = jnp.array(y_train)\n",
        "y_val = jnp.array(y_val)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(type(x_train))\n",
        "print(type(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TsL3MTwc_TC",
        "outputId": "38e477ae-fe3d-4e4d-fd75-9bb147b17dda"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "(54000, 28, 28)\n",
            "(54000,)\n",
            "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
            "<class 'jaxlib.xla_extension.ArrayImpl'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import haiku as hk\n",
        "\n",
        "class MNIST_model(hk.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = hk.Conv2D(output_channels=32, kernel_shape=3, stride=1, padding='SAME')(x)\n",
        "        x = jax.nn.relu(x)\n",
        "        x = hk.MaxPool(window_shape=2, strides=1, padding='SAME')(x)\n",
        "\n",
        "        x = hk.Conv2D(output_channels=64, kernel_shape=3, stride=1, padding='SAME')(x) # increase the number of channels bcz dense layers learn more precise features\n",
        "        x = jax.nn.relu(x)\n",
        "        x = hk.MaxPool(window_shape=2, strides=1, padding='SAME')(x)\n",
        "\n",
        "        x = hk.Flatten()(x) # converting the data into a single column\n",
        "\n",
        "        x = hk.Linear(64)(x)\n",
        "        x = jax.nn.relu(x)\n",
        "\n",
        "        x = hk.Linear(64)(x)\n",
        "        x = jax.nn.relu(x)\n",
        "\n",
        "        x = hk.Linear(self.num_classes)(x)\n",
        "        x = jax.nn.softmax(x)  # Apply softmax activation\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "AHI6MWoYa1z6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_fn(x):\n",
        "    model = MNIST_model(num_classes = 10) # since there are 10 different numbers\n",
        "    return model(x)\n",
        "\n",
        "forward = hk.transform(forward_fn)"
      ],
      "metadata": {
        "id": "5xmjubRzgFcZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rng = jax.random.PRNGKey(42)\n",
        "x_sample = x_train[:1]\n",
        "params = forward.init(rng, x_sample)"
      ],
      "metadata": {
        "id": "ODZbMitfgwhv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)\n",
        "print(y_train[90].shape) # just testing any random\n",
        "print(y_train[120])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P22ynvHxClR",
        "outputId": "c7cd1349-7236-408d-8209-6f6e2845be97"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(54000,)\n",
            "()\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def loss_fn(params, x, y):\n",
        "    predictions = forward.apply(params, None, x)\n",
        "    batch_sz = predictions.shape[0]\n",
        "    log_probs = jnp.log(predictions[jnp.arange(batch_sz), y.astype(int)])\n",
        "    loss = -jnp.mean(log_probs)\n",
        "\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "1Kgm4fXPtrgr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DFFug1wagDe",
        "outputId": "981946a8-faa3-4ae4-e9fe-829760a6f825"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 28, 28)\n",
            "(10000,)\n",
            "(54000, 28, 28)\n",
            "(54000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optax\n",
        "# Initialize optimizer\n",
        "optimizer = optax.adam(1e-3)\n",
        "opt_state = optimizer.init(params)\n",
        "\n",
        "@jax.jit\n",
        "def update(params, opt_state, x, y):\n",
        "    grads = jax.grad(loss_fn)(params, x, y)\n",
        "    updates, opt_state = optimizer.update(grads, opt_state)\n",
        "    new_params = optax.apply_updates(params, updates)\n",
        "\n",
        "    return new_params, opt_state\n",
        "\n",
        "num_epochs = 5\n",
        "batch_size = 64\n",
        "num_batches = x_train.shape[0] # batch_size\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx in range(num_batches):\n",
        "        start_idx = batch_idx * batch_size\n",
        "        end_idx = start_idx + batch_size\n",
        "        x_batch = x_train[start_idx:end_idx]\n",
        "        y_batch = y_train[start_idx:end_idx]\n",
        "\n",
        "        params, opt_state = update(params, opt_state, x_batch, y_batch)\n",
        "\n",
        "        if batch_idx % 1000 == 0:\n",
        "            prediction1 = forward.apply(params,None,x_batch)\n",
        "            accuracy1 = jnp.mean(jnp.argmax(prediction1, axis=-1) == y_batch)\n",
        "            print(f\"Training Accuracy: {accuracy1}\")\n",
        "\n",
        "            train_loss = loss_fn(params, x_batch, y_batch)\n",
        "            val_loss = loss_fn(params, x_val, y_val)\n",
        "\n",
        "            prediction2 = forward.apply(params,None,x_val)\n",
        "            accuracy2 = jnp.mean(jnp.argmax(prediction2, axis=-1) == y_val)\n",
        "            print(f\"Validation Accuracy: {accuracy2}\")\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{num_batches}, Train Loss: {train_loss}, Val Loss: {val_loss}\")\n",
        "            print(\" \")\n",
        "\n",
        "test_loss = loss_fn(params, x_test, y_test)\n",
        "print(f\"Test Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqDGlcIJgEcp",
        "outputId": "6e55cc0b-d5cf-4a6a-c502-1fdd11316de4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.21875\n",
            "Validation Accuracy: 0.1158333346247673\n",
            "Epoch 1/5, Batch 0/54000, Train Loss: 2.2342019081115723, Val Loss: 2.304241895675659\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 1000/54000, Train Loss: nan, Val Loss: 0.30625906586647034\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 2000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 3000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 4000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 5000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 6000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 7000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 8000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 9000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 10000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 11000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 12000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 13000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 14000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 15000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 16000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 17000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 18000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 19000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 20000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 21000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 22000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 23000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 24000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 25000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 26000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 27000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 28000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 29000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 30000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 31000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 32000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 33000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 34000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 35000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 36000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 37000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 38000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 39000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 40000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 41000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 42000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 43000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 44000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 45000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 46000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 47000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 48000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 49000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 50000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 51000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 52000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9026666283607483\n",
            "Epoch 1/5, Batch 53000/54000, Train Loss: nan, Val Loss: 0.3062590956687927\n",
            " \n",
            "Training Accuracy: 0.8125\n",
            "Validation Accuracy: 0.7818333506584167\n",
            "Epoch 2/5, Batch 0/54000, Train Loss: 0.5564518570899963, Val Loss: 0.7167474627494812\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 1000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 2000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 3000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 4000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 5000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 6000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 7000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 8000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 9000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 10000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 11000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 12000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 13000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 14000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 15000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 16000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 17000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 18000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 19000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 20000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 21000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 22000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 23000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 24000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 25000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 26000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 27000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 28000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 29000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 30000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 31000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 32000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 33000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 34000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 35000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 36000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 37000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 38000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 39000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 40000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 41000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 42000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 43000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 44000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 45000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 46000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 47000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 48000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 49000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 50000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 51000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 52000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9390000104904175\n",
            "Epoch 2/5, Batch 53000/54000, Train Loss: nan, Val Loss: 0.21563272178173065\n",
            " \n",
            "Training Accuracy: 1.0\n",
            "Validation Accuracy: 0.9580000042915344\n",
            "Epoch 3/5, Batch 0/54000, Train Loss: 0.004650893155485392, Val Loss: 0.13109059631824493\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 1000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 2000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 3000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 4000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 5000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 6000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 7000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 8000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 9000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 10000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 11000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 12000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 13000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 14000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 15000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 16000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 17000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 18000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 19000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 20000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 21000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 22000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 23000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 24000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 25000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 26000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 27000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 28000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 29000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 30000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 31000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 32000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 33000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 34000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 35000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 36000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 37000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 38000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 39000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 40000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 41000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 42000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 43000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 44000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 45000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 46000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 47000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 48000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 49000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 50000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 51000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 52000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.953666627407074\n",
            "Epoch 3/5, Batch 53000/54000, Train Loss: nan, Val Loss: 0.17112776637077332\n",
            " \n",
            "Training Accuracy: 1.0\n",
            "Validation Accuracy: 0.9631666541099548\n",
            "Epoch 4/5, Batch 0/54000, Train Loss: 0.00043774343794211745, Val Loss: 0.13846902549266815\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 1000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 2000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 3000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 4000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 5000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 6000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 7000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 8000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 9000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 10000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 11000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 12000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 13000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 14000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 15000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 16000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 17000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 18000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 19000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 20000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 21000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 22000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 23000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 24000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 25000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 26000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 27000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 28000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 29000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 30000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 31000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 32000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 33000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 34000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 35000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 36000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 37000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 38000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 39000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 40000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 41000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 42000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 43000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 44000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 45000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 46000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 47000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 48000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 49000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 50000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 51000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 52000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9668332934379578\n",
            "Epoch 4/5, Batch 53000/54000, Train Loss: nan, Val Loss: 0.1209845170378685\n",
            " \n",
            "Training Accuracy: 1.0\n",
            "Validation Accuracy: 0.9696666598320007\n",
            "Epoch 5/5, Batch 0/54000, Train Loss: 0.0002708983374759555, Val Loss: 0.10643810778856277\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 1000/54000, Train Loss: nan, Val Loss: 0.10178015381097794\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 2000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 3000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 4000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 5000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 6000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 7000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 8000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 9000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 10000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 11000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 12000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 13000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 14000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 15000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 16000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 17000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 18000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 19000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 20000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 21000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 22000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 23000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 24000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 25000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 26000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 27000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 28000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 29000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 30000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 31000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 32000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 33000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 34000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 35000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 36000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 37000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 38000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 39000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 40000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 41000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 42000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 43000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 44000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 45000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 46000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 47000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 48000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 49000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 50000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 51000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 52000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Training Accuracy: nan\n",
            "Validation Accuracy: 0.9733332991600037\n",
            "Epoch 5/5, Batch 53000/54000, Train Loss: nan, Val Loss: 0.10178013890981674\n",
            " \n",
            "Test Loss: 0.09151104837656021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for some samples\n",
        "\n",
        "num_samples = 5  # Number of test cases to show predictions for\n",
        "for i in range(num_samples):\n",
        "    x_sample = x_test[i:i+1]\n",
        "    y_true = y_test[i]\n",
        "    logits = forward.apply(params, None, x_sample)\n",
        "    prediction = jnp.argmax(logits, axis=-1)[0]\n",
        "    print(f\"Sample {i+1}: Prediction = {prediction}, True Label = {y_true}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNjAVFkhmCiG",
        "outputId": "5a7825b2-5220-4356-e123-7eeae56561a1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1: Prediction = 7, True Label = 7\n",
            "Sample 2: Prediction = 2, True Label = 2\n",
            "Sample 3: Prediction = 1, True Label = 1\n",
            "Sample 4: Prediction = 0, True Label = 0\n",
            "Sample 5: Prediction = 4, True Label = 4\n"
          ]
        }
      ]
    }
  ]
}
